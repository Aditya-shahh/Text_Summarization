{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2402a17-0573-4526-89be-91c112275fca",
   "metadata": {},
   "source": [
    "### Readme:\n",
    "\n",
    "1. Download the model t5_base.pt\n",
    "2. Download the data .csv files\n",
    "3. Run all the cells till Training.\n",
    "4. In the inference section, specify the path of the model, load the weights and run on test script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35931d-968d-4ec1-93ee-aa703f7f39df",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6011638c-2a03-4f6b-ac54-8e80463f1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import warnings\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "from rouge import Rouge\n",
    "import bert_score\n",
    "\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4188e097-7bb3-49fa-bf77-5e9d760db8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import T5 model and tokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "76621a23-9a47-4eb5-a23d-1115147237cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled   = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d966141-b98b-4f43-87f3-03a86d020e4e",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7c3aaaaa-d718-467d-9ffe-d0755668b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'train_data.csv'\n",
    "val_data_dir = 'val_data.csv'\n",
    "test_data_dir = 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6b22b25e-7a13-493b-8387-be821be5c897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Recent reports have linked some France-based p...</td>\n",
       "      <td>New Welsh Rugby Union chairman Gareth Davies b...</td>\n",
       "      <td>29750031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Army explosives experts were called out to dea...</td>\n",
       "      <td>A suspicious package left outside an Alliance ...</td>\n",
       "      <td>28381580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It has lost its previous triple-A rating from ...</td>\n",
       "      <td>The UK's international reputation for a strong...</td>\n",
       "      <td>34786128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The warning begins at 22:00 GMT on Saturday an...</td>\n",
       "      <td>The Met Office has issued a yellow weather war...</td>\n",
       "      <td>38785939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tony Fisher's body was found by his son in Con...</td>\n",
       "      <td>Two more men have been charged with the murder...</td>\n",
       "      <td>36231761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           document  \\\n",
       "0           0  Recent reports have linked some France-based p...   \n",
       "1           1  Army explosives experts were called out to dea...   \n",
       "2           2  It has lost its previous triple-A rating from ...   \n",
       "3           3  The warning begins at 22:00 GMT on Saturday an...   \n",
       "4           4  Tony Fisher's body was found by his son in Con...   \n",
       "\n",
       "                                             summary        id  \n",
       "0  New Welsh Rugby Union chairman Gareth Davies b...  29750031  \n",
       "1  A suspicious package left outside an Alliance ...  28381580  \n",
       "2  The UK's international reputation for a strong...  34786128  \n",
       "3  The Met Office has issued a yellow weather war...  38785939  \n",
       "4  Two more men have been charged with the murder...  36231761  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_data_dir)\n",
    "val_df = pd.read_csv(val_data_dir)\n",
    "test_df = pd.read_csv(test_data_dir)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "aa94c5fd-905c-43ff-91cf-d7cc0e99d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df['document'].to_list()\n",
    "train_labels = train_df['summary'].to_list()\n",
    "\n",
    "val_data = val_df['document'].to_list()\n",
    "val_labels = val_df['summary'].to_list()\n",
    "\n",
    "test_data = test_df['document'].to_list()\n",
    "test_labels = test_df['summary'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09960677-be59-49c6-ba0f-d574bb14c19f",
   "metadata": {},
   "source": [
    "### Threshold summary\n",
    "We set the threshold summary length to 3 words. \n",
    "So those data with summary less than 3 words will be discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "feed9017-6486-459a-89db-c76800464f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(train_labels):\n",
    "    item = str(data).replace('\\n', '')\n",
    "    item = item.split()\n",
    "    if len(item) < 3:\n",
    "        train_labels.remove(data)\n",
    "        train_data.remove(train_data[idx])\n",
    "\n",
    "        \n",
    "for idx, data in enumerate(val_labels):\n",
    "    item = str(data).replace('\\n', '')\n",
    "    item = item.split()\n",
    "    if len(item) < 3:\n",
    "        val_labels.remove(data)\n",
    "        val_data.remove(val_data[idx])\n",
    "        \n",
    "for idx, data in enumerate(test_labels):\n",
    "    item = str(data).replace('\\n', '')\n",
    "    item = item.split()\n",
    "    if len(item) < 3:\n",
    "        test_labels.remove(data)\n",
    "        test_data.remove(test_data[idx])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c0d09d19-585c-47c3-9f2a-2efdcd88f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_len = []\n",
    "train_label_len = []\n",
    "\n",
    "for item in train_data:\n",
    "    item = str(item).replace('\\n', ' ')\n",
    "    item = item.split()\n",
    "    train_data_len.append(len(item))\n",
    "\n",
    "for item in train_labels:\n",
    "    item = str(item).replace('\\n', '')\n",
    "    item = item.split()\n",
    "    train_label_len.append(len(item))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "91da61da-d061-44f0-a804-609c3f6cbfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33c565ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(train_label_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f51de6d-0e6c-4c71-b021-0c91b207e00b",
   "metadata": {},
   "source": [
    "Now minimum summary length is 3 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8896efe7-337e-4dfc-9ece-1dc3e9d2a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_label_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4453f23-b04e-49b0-bde6-361ca895d997",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82432997-9162-4a7e-9d24-ef448e4a9c28",
   "metadata": {},
   "source": [
    "Tokenize the source and summary. Also, adds a special task prefix \"summarize:\" in the start of every input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dcc9701e-ba38-4f3a-8b3e-8ab959f3bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SummaryData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, data, summary, input_length, output_length):     \n",
    "        \n",
    "        \n",
    "\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "        self.data = data\n",
    "        self.summary = summary\n",
    "\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.summary)\n",
    "    \n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        text = self.data[idx]\n",
    "        summary = self.summary[idx]\n",
    "        \n",
    "        task_prefix = \"summarize: \"\n",
    "        \n",
    "        text = task_prefix + str(text)\n",
    "        \n",
    "        source = tokenizer.encode_plus(str(text), max_length=self.input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        summary = tokenizer.encode_plus(str(summary), max_length=self.output_length, padding='max_length', truncation=True)\n",
    "        \n",
    "    \n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        src_mask    = source[\"attention_mask\"].squeeze()\n",
    "        \n",
    "        summary_ids = summary[\"input_ids\"]\n",
    "        \n",
    "        summary_ids = [(label if label != tokenizer.pad_token_id else -100) for label in summary_ids]\n",
    "        summary_ids = torch.tensor(summary_ids)\n",
    "\n",
    "        \n",
    "\n",
    "        return {\"input_ids\": source_ids, \"attention_mask\": src_mask, \"labels\": summary_ids, 'ground_truth': self.summary[idx] }\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9b37b-f6cb-4765-90e7-0824a40a050e",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "89e303dd-1e59-4788-a389-388c1e3b4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the Hyper parameters \n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-4\n",
    "CLIP = 5\n",
    "\n",
    "\n",
    "input_length = 512\n",
    "output_length = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6d0dd26c-221b-47e6-b9a7-8165105e6869",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4e8a1496-72e9-4ccd-a80e-75dccdd8529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": LEARNING_RATE,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "   \"architecture\": \"T5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e83fd-8c78-4ebf-a0d6-cecde634c915",
   "metadata": {},
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "403d2981-b5b8-4263-9ad0-252094f910b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SummaryData(tokenizer, train_data, train_labels, input_length, output_length)\n",
    "val_dataset = SummaryData(tokenizer, val_data, val_labels, input_length, output_length)\n",
    "test_dataset = SummaryData(tokenizer, test_data, test_labels,input_length, output_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f5462-b38b-4c87-86a1-84608e8df27e",
   "metadata": {},
   "source": [
    "### Load the T5 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "849fa894-d174-47d5-8241-01b090c6600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0ffee3e9-af14-4b08-851e-bf2d0e5a4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## We call the dataloader class\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "dataloaders = {'Train': train_loader, 'Test': test_loader, 'Val': val_loader}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e631a756-e260-4544-a7dd-1dbf2dd6790f",
   "metadata": {},
   "source": [
    "### Optimizer and Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1d67e95f-e99a-4def-bcf4-65fcc55d1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps=1e-8 )\n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01442d-b830-4b4e-b76e-f27de6c649d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54946f59-5597-4f37-96db-bc279586df06",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6dc17e7c-105c-41b7-aa54-7e2db70a7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 't5_base.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efd9490e-0efe-472a-bd82-a72a8697cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 12749/12749 [1:25:08<00:00,  2.50batch/s, loss=2.6] \n",
      "Val: 100%|██████████| 708/708 [34:04<00:00,  2.89s/batch, f_score=0.084, precision=0.0722, recall=0.106]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "--------------------------------------------------\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 12749/12749 [1:22:25<00:00,  2.58batch/s, loss=2.4] \n",
      "Val: 100%|██████████| 708/708 [33:43<00:00,  2.86s/batch, f_score=0.0907, precision=0.0778, recall=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "--------------------------------------------------\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 12749/12749 [1:22:33<00:00,  2.57batch/s, loss=2.3]\n",
      "Val: 100%|██████████| 708/708 [38:38<00:00,  3.27s/batch, f_score=0.0973, precision=0.0835, recall=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "best_valid_f = 0.000\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "  \n",
    "\n",
    "    print('-'*50)\n",
    "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
    "    \n",
    "    scores = []\n",
    "    f_score = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    \n",
    "    batch_loss = 0.0000\n",
    "\n",
    "    for phase in ['Train', 'Val']:\n",
    "\n",
    "        if phase == 'Train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "            \n",
    "        \n",
    "        with tqdm(dataloaders[phase], unit=\"batch\", desc=phase) as tepoch:\n",
    "\n",
    "          for idx, batch in enumerate(tepoch):\n",
    "            \n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                \n",
    "                attention_mask =  batch['attention_mask'].to(device)\n",
    "                \n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                ground_truth = batch['ground_truth']\n",
    "                \n",
    "                if phase == 'Train':\n",
    "                \n",
    "                    out = model(input_ids = input_ids, attention_mask = attention_mask, labels = labels)\n",
    "\n",
    "                    loss = out.loss\n",
    "                    \n",
    "                    batch_loss += loss.item()\n",
    "                    \n",
    "                    #zero gradients\n",
    "                    optimizer.zero_grad() \n",
    "\n",
    "                    # Backward pass  (calculates the gradients)\n",
    "                    loss.backward()   \n",
    "\n",
    "                    # gradient clipping\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), CLIP)    \n",
    "\n",
    "                    optimizer.step()             # Updates the weights\n",
    "                    \n",
    "                    tepoch.set_postfix(loss = batch_loss/(idx+1))\n",
    "                    \n",
    "                    wandb.log({\"Train loss\": batch_loss/(idx+1)})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    out = model.generate(input_ids= input_ids, attention_mask =  attention_mask, do_sample=False)\n",
    "                    preds = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "                    \n",
    "                    #get rouge score\n",
    "                    score = rouge.get_scores(preds, ground_truth)\n",
    "                    \n",
    "                    scores.extend(score)\n",
    "\n",
    "                    \n",
    "                    for item in scores:\n",
    "                        rouge_2 = item['rouge-2']\n",
    "                        f_score.append(rouge_2['f'])\n",
    "                        recall.append(rouge_2['p'])\n",
    "                        precision.append(rouge_2['r'])\n",
    "                        \n",
    "                    \n",
    "                    tepoch.set_postfix(f_score=np.mean(np.array(f_score)), recall= np.mean(np.array(recall)), precision = np.mean(np.array(precision)) )\n",
    "                   \n",
    "                    wandb.log({'Val f_score': np.mean(np.array(f_score))})\n",
    "                    \n",
    "                    wandb.log({'Val precision': np.mean(np.array(precision))})\n",
    "                    \n",
    "                    wandb.log({'Val recall': np.mean(np.array(recall))})\n",
    "                    \n",
    "    \n",
    "                    \n",
    "                \n",
    "\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print('Model Saved!')\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd0acb-2b98-48cd-af91-56e8c6f3c4db",
   "metadata": {},
   "source": [
    "### Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c69b284-6376-4d3c-87a7-9625441d9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 't5_base.pt'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1b37eec-cf5b-4c8f-a6ee-9daf81368fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b04cb-c122-4926-beb5-c0db553a5240",
   "metadata": {},
   "source": [
    "Test script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bfb25629-1744-485d-9190-5e52c87d14a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 1416/1416 [05:11<00:00,  4.55batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rouge-2:  f: 0.0950, p: 0.0817, r : 0.1193.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set the model to evaluation mode            \n",
    "model.eval()\n",
    "\n",
    "scores = []\n",
    "\n",
    "f_score = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "predicted  = []\n",
    "true = []\n",
    "        \n",
    "with tqdm(test_loader, unit=\"batch\", desc= \"Test\") as tepoch:\n",
    "    \n",
    "  for batch in tepoch:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "                \n",
    "    attention_mask =  batch['attention_mask'].to(device)\n",
    "                \n",
    "    labels = batch['labels'].to(device)\n",
    "                \n",
    "    ground_truth = batch['ground_truth']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        out = model.generate(input_ids= input_ids, attention_mask =  attention_mask, do_sample=False)\n",
    "        \n",
    "        preds = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "        \n",
    "        predicted.extend(preds)\n",
    "        true.extend(ground_truth)\n",
    "                    \n",
    "        #get rouge score\n",
    "        score = rouge.get_scores(preds, ground_truth)\n",
    "                    \n",
    "        scores.extend(score)\n",
    "                                \n",
    "\n",
    "for item in scores:\n",
    "    \n",
    "    rouge_2 = item['rouge-2']\n",
    "    f_score.append(rouge_2['f'])\n",
    "    recall.append(rouge_2['p'])\n",
    "    precision.append(rouge_2['r'])\n",
    "        \n",
    "f = np.mean(np.array(f_score))\n",
    "    \n",
    "p = np.mean(np.array(precision))\n",
    "    \n",
    "r = np.mean(np.array(recall))\n",
    "\n",
    "print(\"Test Rouge-2:  f: {:.4f}, p: {:.4f}, r : {:.4f}.\".format(f, p, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112f603-b2e3-4b69-8413-eb5074331357",
   "metadata": {},
   "source": [
    "### Visualize rouge_2 f values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4351385-cdbb-4009-a152-6e29398345d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0fec3f14-eee7-4117-a056-cbf1ca482e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11333/11333 [1:05:30<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(test_dataset))):\n",
    "    \n",
    "    input_ids = test_dataset[index]['input_ids'].unsqueeze(0).to(device)\n",
    "    input_text = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "    attention_mask = test_dataset[index]['attention_mask'].unsqueeze(0).to(device)\n",
    "\n",
    "    summary = test_dataset[index]['ground_truth']\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        output = model.generate(input_ids= input_ids, attention_mask =  attention_mask, do_sample=False)\n",
    "\n",
    "        predicted = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "        \n",
    "        score2 = rouge.get_scores(predicted[0], summary)\n",
    "        \n",
    "        scores2.extend(score2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2eafd52-f94a-4afe-bd5c-464fbcf46bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score2 = []\n",
    "recall2 = []\n",
    "precision2 = []\n",
    "\n",
    "for item in scores2:\n",
    "    \n",
    "    rouge_2 = item['rouge-2']\n",
    "    f_score2.append(rouge_2['f'])\n",
    "    recall2.append(rouge_2['p'])\n",
    "    precision2.append(rouge_2['r'])\n",
    "        \n",
    "f = np.mean(np.array(f_score2))\n",
    "    \n",
    "p = np.mean(np.array(recall2))\n",
    "    \n",
    "r = np.mean(np.array(precision2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e7960b34-2667-4035-8537-d9d7da2dd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of f scores \n",
    "\n",
    "\n",
    "indices_0 = [i for i,v in enumerate(f_score2) if v == 0.00]\n",
    "indices_2 = [i for i,v in enumerate(f_score2) if v > 0.00 and v <= 0.04]\n",
    "indices_3 = [i for i,v in enumerate(f_score2) if v > 0.04 and v <= 0.08]\n",
    "indices_4 = [i for i,v in enumerate(f_score2) if v > 0.08 and v <= 0.15]\n",
    "indices_5 = [i for i,v in enumerate(f_score2) if v > 0.15 and v <= 0.3]\n",
    "indices_6 = [i for i,v in enumerate(f_score2) if v > 0.3 and v <= 0.5]\n",
    "indices_7 = [i for i,v in enumerate(f_score2) if v > 0.5 and v <= 0.7]\n",
    "indices_8 = [i for i,v in enumerate(f_score2) if v > 0.7 and v <= 0.9]\n",
    "indices_9 = [i for i,v in enumerate(f_score2) if v > 0.9 and v <= 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "14a7cd1f-2a89-4b39-94be-4e764706fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0 = len(indices_0)\n",
    "count_2 = len(indices_2)\n",
    "count_3 = len(indices_3)\n",
    "count_4 = len(indices_4)\n",
    "count_5 = len(indices_5)\n",
    "count_6 = len(indices_6)\n",
    "count_7 = len(indices_7)\n",
    "count_8 = len(indices_8)\n",
    "count_9 = len(indices_9)\n",
    "\n",
    "\n",
    "count = [count_0, count_2, count_3, count_4, count_5, count_6, count_7, count_8, count_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c3b820ec-dd1b-4389-a386-81cf4202b745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4143, 19, 2693, 1873, 1893, 621, 64, 15, 12]\n"
     ]
    }
   ],
   "source": [
    "# count of values for different f scores\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "65481083-fe69-49e1-8743-243296b36472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[459, 722, 748, 950, 1407, 2212, 2293, 2428, 5062, 6050, 7305, 7502, 8077, 8809, 9740]\n"
     ]
    }
   ],
   "source": [
    "#Indices of samples that generate perfect summary\n",
    "print(indices_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972f9d9b-5b4c-4791-bbf5-a7c7d3140456",
   "metadata": {},
   "source": [
    "Count of f2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "717b0b88-ac79-466b-8ec8-bb6cedd38b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30fce81550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    " \n",
    "# Plotting the Graph\n",
    "plt.hist(f_score2, bins = 1000)\n",
    "plt.title(\"Count for f values\")\n",
    "plt.xlabel(\"rouge_2 f value\")\n",
    "plt.ylabel(\"No. of samples\")\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78cfa3-bb09-49ea-888e-29b6916c6120",
   "metadata": {},
   "source": [
    "### Analyze Outputs:\n",
    "\n",
    "Take 1 example from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "adaddfa0-7308-4f08-95cd-5ef024d01398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: summarize: A selection of your pictures of Scotland sent in between 6 and 13 January. Send your photos to scotlandpictures@bbc.co.uk or our Instagram at #bbcscotlandpics.\n",
      "\n",
      "Ground Truth: All pictures are copyrighted.\n",
      "\n",
      "Predicted: All pictures are copyrighted.\n"
     ]
    }
   ],
   "source": [
    "index  = 756\n",
    "input_ids = test_dataset[index]['input_ids'].unsqueeze(0).to(device)\n",
    "input_text = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "attention_mask = test_dataset[index]['attention_mask'].unsqueeze(0).to(device)\n",
    "\n",
    "summary = test_dataset[index]['ground_truth']\n",
    "    \n",
    "output = model.generate(input_ids= input_ids, attention_mask =  attention_mask, do_sample=False)\n",
    "\n",
    "predicted = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print('Input Text:', input_text[0])\n",
    "print()\n",
    "print(\"Ground Truth:\", summary) \n",
    "print()\n",
    "print(\"Predicted:\", predicted[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bd9cce15-7ab2-4275-aab1-1e8caeb5d904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: summarize: If you have a picture you would like to share, please see below the images for details on how to submit yours. If you have a picture you'd like to share, email us at england@bbc.co.uk, post it on Facebook or tweet it to @BBCEngland. You can also find us on Instagram - use #englandsbigpicture to share an image there. When emailing pictures, please make sure you include the following information: Please note that whilst we welcome all your pictures, we are more likely to use those which have been taken in the past week. If you submit a picture, you do so in accordance with the BBC's Terms and Conditions. In contributing to England's Big Picture you agree to grant us a royalty-free, non-exclusive licence to publish and otherwise use the material in any way that we want, and in any media worldwide. It's important to note, however, that you still own the copyright to everything you contribute to England's Big Picture, and that if your image is accepted, we will publish your name alongside. The BBC cannot guarantee that all pictures will be used and we reserve the right to edit your comments. At no time should you endanger yourself or others, take any unnecessary risks or infringe any laws collecting any kind of media.\n",
      "\n",
      "Ground Truth: Each day we feature a photograph sent in from across England - the gallery will grow during the week.\n",
      "\n",
      "Predicted: Each day we feature a photograph sent in from across England - the gallery will grow during\n"
     ]
    }
   ],
   "source": [
    "index  = 4747\n",
    "input_ids = test_dataset[index]['input_ids'].unsqueeze(0).to(device)\n",
    "input_text = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "attention_mask = test_dataset[index]['attention_mask'].unsqueeze(0).to(device)\n",
    "\n",
    "summary = test_dataset[index]['ground_truth']\n",
    "    \n",
    "output = model.generate(input_ids= input_ids, attention_mask =  attention_mask, do_sample=False)\n",
    "\n",
    "predicted = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print('Input Text:', input_text[0])\n",
    "print()\n",
    "print(\"Ground Truth:\", summary) \n",
    "print()\n",
    "print(\"Predicted:\", predicted[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c8858093-9478-4d8b-9de7-a3bf5b5dfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: summarize: The 24-year-old was an injury-time substitute for the Cherries in their 2-1 win at Aston Villa on Saturday. Wilson, Bournemouth's leading scorer last season, missed six months of the club's first Premier League campaign with medial knee ligament damage. \"There's nothing like being back out on the pitch,\" he told BBC Radio Solent. \"It was only a few touches, but it's nice to feel like a football player again.\" The former Coventry City striker required surgery following the injury he sustained against Stoke in September and revealed his return came a week earlier than planned. \"I'd originally targeted the Liverpool game (at home on Sunday), but one week sooner is perfect for me,\" added Wilson. \"There's a little bit of match fitness still to regain, but I feel strong and ready.\"\n",
      "\n",
      "Ground Truth: Bournemouth striker Callum Wilson said it was \"great to feel like a football player again\" as he returned to action following a long-term injury.\n",
      "\n",
      "Predicted: Bournemouth striker Ryan Wilson says he feels like a footballer again after\n"
     ]
    }
   ],
   "source": [
    "index  = 231\n",
    "input_ids = test_dataset[index]['input_ids'].unsqueeze(0).to(device)\n",
    "input_text = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "attention_mask = test_dataset[index]['attention_mask'].unsqueeze(0).to(device)\n",
    "\n",
    "summary = test_dataset[index]['ground_truth']\n",
    "    \n",
    "output = model.generate(input_ids= input_ids, attention_mask =  attention_mask, do_sample=False)\n",
    "\n",
    "predicted = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print('Input Text:', input_text[0])\n",
    "print()\n",
    "print(\"Ground Truth:\", summary) \n",
    "print()\n",
    "print(\"Predicted:\", predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b44d4723-770d-4376-b26d-2c57ae255b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 8, 11, 12, 17, 18, 23, 25, 27, 30, 32, 35, 37, 41, 43, 48, 50, 52, 55, 56, 58, 61, 62, 63, 64, 66, 67, 69, 70, 73, 78, 80, 81, 82, 85, 93, 95, 97, 101, 102]\n"
     ]
    }
   ],
   "source": [
    "#samples that have 0 f score\n",
    "print(indices_0[:41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "37f94ec0-518e-420a-8528-0f283b7cbdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: summarize: Michael D Higgins will ask the Council of State if the Protection of Life During Pregnancy Bill's legality should be tested by the Supreme Court. The bill would allow a termination when doctors deem that a woman is at risk of taking her life. President Higgins must decide by Wednesday whether to sign the bill into law or refer it to the court. If the Supreme Court decides it is constitutional and approves the bill, it will automatically become law and its constitutionality could never be subsequently challenged. It the first time that President Higgins has convened the Council of State since he assumed office in November 2011. The Council of State is an advisory body that aids and counsels the president. The introduction of the legislation follows the case of an Indian woman who died in an Irish hospital after she was refused an abortion. The debate revealed deep splits in the predominantly Catholic country. Anti-abortion campaigners say that the bill will allow the intentional killing of the unborn for the first time in the Republic of Ireland. Others argue the bill is too limited as it does not allow for terminations in cases of rape or incest, or when there is a foetal abnormality or when the foetus cannot survive outside the womb. Since a Supreme Court ruling in the 1992 X case, abortion has been constitutionally available when a woman's life, as distinct from her health, is at risk from the continued pregnancy. X was a suicidal 14-year-old schoolgirl who had been raped by a neighbour and was initially prevented from leaving the country for an abortion in Britain. Since then, the credible threat of suicide is, constitutionally, regarded as grounds for a termination. But until now, no government in the republic has introduced legislation to give doctors legal certainty on when an abortion can be carried out. That uncertainty provided part of the context for the Savita Halappanavar case. She was a 31-year-old Indian dentist who was admitted to hospital in Galway in October 2012 while miscarrying. She died a week later from septicaemia. Her request for an abortion was turned down. Her inquest heard that she could not get a termination at the time because her life was not in danger but, by the time her life was at risk, an abortion would have been too\n",
      "\n",
      "Ground Truth: A bill giving limited access to abortion has been referred to an advisory body by Ireland's president.\n",
      "\n",
      "Predicted: The President of the Republic of Ireland is to ask the Supreme Court to consider a bill that\n"
     ]
    }
   ],
   "source": [
    "index  = 101\n",
    "input_ids = test_dataset[index]['input_ids'].unsqueeze(0).to(device)\n",
    "input_text = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "attention_mask = test_dataset[index]['attention_mask'].unsqueeze(0).to(device)\n",
    "\n",
    "summary = test_dataset[index]['ground_truth']\n",
    "    \n",
    "output = model.generate(input_ids= input_ids, attention_mask =  attention_mask, do_sample=False)\n",
    "\n",
    "predicted = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print('Input Text:', input_text[0])\n",
    "print()\n",
    "print(\"Ground Truth:\", summary) \n",
    "print()\n",
    "print(\"Predicted:\", predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "744baece-c362-4131-aacd-e7362f71e2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.12903225306971924, 'p': 0.13333333333333333, 'r': 0.125},\n",
       "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
       "  'rouge-l': {'f': 0.06451612403746138,\n",
       "   'p': 0.06666666666666667,\n",
       "   'r': 0.0625}}]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(predicted[0], summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71bde4-0c1a-42d1-99e0-8eb980658057",
   "metadata": {},
   "source": [
    "### Using BERT SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a602f059-0ce1-4ea8-b8bc-fe3550ab4196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f636f80ae3341ee9438a32162a83139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbba359aae14b32ae2ca6553723e2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.05 seconds, 18.32 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "predicted = ['Perfect day for hiking']\n",
    "true = ['Such a beautiful weather for trekking']\n",
    "\n",
    "P, R, F1 = score(predicted, true, lang='en', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e4eabb96-be14-4a67-9207-79a37aa3e9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9209]), tensor([0.9093]), tensor([0.9151]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P, R, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1fca06e6-f691-4d92-ab4d-b130f8dd65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e5d142743e491f8bf597cd7e17858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa6f8442f124f44979445830a2b01f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.06 seconds, 16.40 sentences/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.9026]), tensor([0.8882]), tensor([0.8953]))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "true = [summary]\n",
    "\n",
    "P, R, F1 = score(predicted, true, lang='en', verbose=True)\n",
    "\n",
    "P, R, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f27ff056-8064-4eb4-9a6c-569ce9ff250a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The President of the Republic of Ireland is to ask the Supreme Court to consider a bill that']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3062bf-2454-4e4a-94ab-0c0755bf55c1",
   "metadata": {},
   "source": [
    "### BERT score on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "21da38e6-fc21-41ff-9232-d65adfe9fb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 1416/1416 [05:22<00:00,  4.40batch/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set the model to evaluation mode            \n",
    "model.eval()\n",
    "\n",
    "scores = []\n",
    "\n",
    "f_score = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "predicted  = []\n",
    "true = []\n",
    "        \n",
    "with tqdm(test_loader, unit=\"batch\", desc= \"Test\") as tepoch:\n",
    "    \n",
    "  for batch in tepoch:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "                \n",
    "    attention_mask =  batch['attention_mask'].to(device)\n",
    "                \n",
    "    labels = batch['labels'].to(device)\n",
    "                \n",
    "    ground_truth = batch['ground_truth']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        out = model.generate(input_ids= input_ids, attention_mask =  attention_mask, do_sample=False)\n",
    "        \n",
    "        preds = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "        \n",
    "        predicted.extend(preds)\n",
    "        true.extend(ground_truth)\n",
    "                    \n",
    "        #get rouge score\n",
    "        score = rouge.get_scores(preds, ground_truth)\n",
    "                    \n",
    "        scores.extend(score)\n",
    "                                \n",
    "\n",
    "for item in scores:\n",
    "    \n",
    "    rouge_2 = item['rouge-2']\n",
    "    f_score.append(rouge_2['f'])\n",
    "    recall.append(rouge_2['p'])\n",
    "    precision.append(rouge_2['r'])\n",
    "    \n",
    "\n",
    "f = np.mean(np.array(f_score))\n",
    "    \n",
    "p = np.mean(np.array(precision))\n",
    "    \n",
    "r = np.mean(np.array(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b86c92e0-4ab0-47f9-99d9-b8fd1eb67980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11328, 11328)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted), len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "82c60734-f5ea-4e16-bb43-a067ca77963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1507f6345f4a0ca16b658f21a00dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/354 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e256c3734864b7a9933d94af143a184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 41.34 seconds, 274.02 sentences/sec\n",
      "Test BERT score: f: 0.8837, p: 0.8932, r : 0.8745.\n",
      "Test Rouge-2:  f: 0.0950, p: 0.0816, r : 0.1193.\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "P, R, F1 = score(predicted, true, lang='en', verbose=True)\n",
    "\n",
    "print(\"Test BERT score: f: {:.4f}, p: {:.4f}, r : {:.4f}.\".format(F1.mean(), P.mean(), R.mean()))\n",
    "\n",
    "print(\"Test Rouge-2:  f: {:.4f}, p: {:.4f}, r : {:.4f}.\".format(f, p, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d72d31-93dc-48c9-ad5f-1b551671dcaa",
   "metadata": {},
   "source": [
    "### WCN on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f98a7ad2-a494-4c37-9bb5-524f19cca16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WCN Score on Test data:  f: 0.3579, p: 0.3711, r : 0.3522.\n"
     ]
    }
   ],
   "source": [
    "f_score_mix = []\n",
    "recall_mix = []\n",
    "precision_mix = []\n",
    "\n",
    "\n",
    "#get rouge_2 and rouge_1 metrics\n",
    "for item in scores:\n",
    "    \n",
    "    rouge_2 = item['rouge-2']\n",
    "    f_score_mix.append(rouge_2['f'])\n",
    "    recall_mix.append(rouge_2['p'])\n",
    "    precision_mix.append(rouge_2['r'])\n",
    "\n",
    "    rouge_1 = item['rouge-1']\n",
    "    f_score_mix.append(rouge_2['f'])\n",
    "    recall_mix.append(rouge_2['p'])\n",
    "    precision_mix.append(rouge_2['r'])\n",
    "    \n",
    "\n",
    "# get bertscore    \n",
    "f_score_mix.extend(F1.detach().cpu().numpy().tolist())\n",
    "recall_mix.extend(R.detach().cpu().numpy().tolist())\n",
    "precision_mix.extend(P.detach().cpu().numpy().tolist())\n",
    "    \n",
    "    \n",
    "# take the average\n",
    "f = np.mean(np.array(f_score_mix))\n",
    "    \n",
    "p = np.mean(np.array(recall_mix))\n",
    "    \n",
    "r = np.mean(np.array(precision_mix))\n",
    "\n",
    "print(\"WCN Score on Test data:  f: {:.4f}, p: {:.4f}, r : {:.4f}.\".format(f, p, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52726ea5-031d-4eb6-a2c3-1e41e2db15b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
